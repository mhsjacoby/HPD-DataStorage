{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from my_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dictionaries with days to include for each home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_dict = {\n",
    "    'H1': [['2019-11-26',' 2019-12-25']], \n",
    "    'H2': [['2019-03-13', '2019-03-29']], \n",
    "    'H3': [['2019-07-23', '2019-08-04'], ['2019-08-15', '2019-09-05']], \n",
    "    'H4': [['2019-05-01', '2019-05-12'], ['2019-05-17', '2019-05-21']],\n",
    "    'H5': [['2019-06-07', '2019-06-21']],\n",
    "    'H6': [['2019-10-12', '2019-11-02'], ['2019-11-20', '2019-12-05']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 30\n",
      "H2 17\n",
      "H3 35\n",
      "H4 17\n",
      "H5 15\n",
      "H6 38\n"
     ]
    }
   ],
   "source": [
    "all_days_dict = {}\n",
    "\n",
    "for home in start_end_dict:\n",
    "    home_st = start_end_dict[home]\n",
    "    all_days = []\n",
    "\n",
    "    for st in home_st:\n",
    "        start, end = st[0], st[1]\n",
    "        pd_days = pd.date_range(start=start, end=end).tolist()\n",
    "        days = [d.strftime('%Y-%m-%d') for d in pd_days]\n",
    "        all_days.extend(days)\n",
    "        \n",
    "    all_days_dict[home] = all_days\n",
    "\n",
    "for h in all_days_dict:\n",
    "    print(h, len(all_days_dict[h]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Whole sheet inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/Users/maggie/Desktop/HDstorage'\n",
    "\n",
    "# dest = '/Volumes/SAMSUNG-4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3\n",
      "/Volumes/TOSHIBA-13/H3-red/RS1\n",
      "/Volumes/TOSHIBA-13/H3-red/RS2\n",
      "/Volumes/TOSHIBA-13/H3-red/RS3\n",
      "/Volumes/TOSHIBA-13/H3-red/RS4\n",
      "/Volumes/TOSHIBA-13/H3-red/RS5\n"
     ]
    }
   ],
   "source": [
    "from_path = '/Volumes/TOSHIBA-13/H3-red/'\n",
    "\n",
    "home, c = os.path.basename(from_path.strip('/')).split('-')\n",
    "color = c[0].upper()\n",
    "\n",
    "hub_paths = glob(os.path.join(from_path, f'{color}S*'))\n",
    "\n",
    "print(home)\n",
    "for hub in hub_paths:\n",
    "    print(hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Dark Image Lists\n",
    "should be in form: \n",
    "`HOME_DARKIMAGES.zip/HOME_HUB_DARKIMAGES/date_hub_home_dark-images.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewrite Dark image JSON files to csvs and rename storage directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS1\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES\n",
      "RS2\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES\n",
      "RS3\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS3_DARKIMAGES\n",
      "RS4\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES\n",
      "RS5\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES\n"
     ]
    }
   ],
   "source": [
    "save_loc = make_storage_directory(os.path.join(save_path, home, f'{home}_DARKIMAGES'))\n",
    "\n",
    "\n",
    "for hub_path in hub_paths:\n",
    "    hub = os.path.basename(hub_path.strip('/'))\n",
    "    print(hub)\n",
    "    save_dirname = f'{home}_{hub}_DARKIMAGES'\n",
    "    print(os.path.join(save_loc, save_dirname))\n",
    "    \n",
    "    save_hub_dir = make_storage_directory(os.path.join(save_loc, save_dirname))\n",
    "    for json_file in glob(os.path.join(hub_path, '*-img-pkl', 'black_image_dicts', '*.json')):\n",
    "        day = os.path.basename(json_file).strip('_dark_images.json')\n",
    "        with open(json_file) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            times = []\n",
    "            for key in data:\n",
    "                times.extend(data[key])\n",
    "        timestamps = sorted([datetime.strptime(f'{day} {time}', '%Y-%m-%d %H%M%S') for time in times])\n",
    "        timestamps = [[ts] for ts in timestamps]\n",
    "\n",
    "        csv_file = os.path.join(save_hub_dir, f'{day}_{hub}_{home}_darkimages.csv')\n",
    "        write_file = open(csv_file, 'w+')\n",
    "        with write_file:\n",
    "            csv_writer = csv.writer(write_file)\n",
    "            csv_writer.writerows(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def delete_days(home_path, modality_path, delete=False):\n",
    "    for hub_dir in sorted(glob(os.path.join(home_path, modality_path))):\n",
    "        print(hub_dir)\n",
    "        files = glob(os.path.join(hub_dir, '*_darkimages.csv'))\n",
    "        del_files = [f for f in files if os.path.basename(f).split('_')[0] not in all_days_dict[home]]\n",
    "        if delete:\n",
    "            for file_to_delete in sorted(del_files):\n",
    "                os.remove(file_to_delete)\n",
    "                print('deleted:', file_to_delete)\n",
    "        else:\n",
    "            print('Testing (nothing deleted)')\n",
    "            for file_to_delete in sorted(del_files):\n",
    "                print(file_to_delete)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-07-16_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-07-17_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-07-18_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-07-19_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-07-20_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-07-21_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-07-22_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-08-05_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-08-12_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-08-14_RS1_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS1_DARKIMAGES/2019-09-06_RS1_H3_darkimages.csv\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-07-16_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-07-17_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-07-18_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-07-19_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-07-20_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-07-21_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-07-22_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-08-05_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-08-12_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-08-14_RS2_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS2_DARKIMAGES/2019-09-06_RS2_H3_darkimages.csv\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS3_DARKIMAGES\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS3_DARKIMAGES/2019-07-16_RS3_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS3_DARKIMAGES/2019-07-22_RS3_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS3_DARKIMAGES/2019-08-05_RS3_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS3_DARKIMAGES/2019-08-12_RS3_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS3_DARKIMAGES/2019-08-14_RS3_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS3_DARKIMAGES/2019-09-06_RS3_H3_darkimages.csv\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-06-26_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-06-27_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-06-28_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-06-29_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-06-30_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-07-01_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-07-16_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-07-17_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-07-18_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-07-19_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-07-20_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-07-21_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-07-22_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-08-05_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-08-12_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-08-14_RS4_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS4_DARKIMAGES/2019-09-06_RS4_H3_darkimages.csv\n",
      "/Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-06-26_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-06-27_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-06-28_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-06-29_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-06-30_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-07-01_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-07-16_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-07-17_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-07-18_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-07-19_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-07-20_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-07-21_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-07-22_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-08-05_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-08-12_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-08-14_RS5_H3_darkimages.csv\n",
      "deleted: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES/H3_RS5_DARKIMAGES/2019-09-06_RS5_H3_darkimages.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "delete_days(os.path.join(save_path, home), modality_path = '*_DARKIMAGES/*_DARKIMAGES', delete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress dark image files to harddrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: /Users/maggie/Desktop/HDstorage/H3/H3_DARKIMAGES to: /Volumes/SAMSUNG-4/H3/H3_DARKIMAGES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Volumes/SAMSUNG-4/H3/H3_DARKIMAGES.zip'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "directory_path = '/Users/maggie/Desktop/HDstorage'\n",
    "\n",
    "to_path = make_storage_directory(os.path.join(dest, home))\n",
    "\n",
    "to_compress = os.path.join(directory_path, home, f'{home}_DARKIMAGES')\n",
    "destination = os.path.join(to_path, os.path.basename(to_compress.strip('/')))\n",
    "\n",
    "print(f'from: {to_compress} to: {destination}')\n",
    "shutil.make_archive(destination, 'zip', to_compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move image day-files not part of the set to an archive folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS1 35 0\n",
      "RS2 35 0\n",
      "RS3 35 0\n",
      "RS4 35 0\n",
      "RS5 35 0\n"
     ]
    }
   ],
   "source": [
    "for hub_path in hub_paths:\n",
    "    hub = os.path.basename(hub_path.strip('/'))\n",
    "    day_files = glob(os.path.join(hub_path, 'img-downsized-32', '2019-*'))\n",
    "    move_files = [f for f in day_files if os.path.basename(f) not in all_days_dict[home]]\n",
    "    print(hub, len(day_files), len(move_files))\n",
    "#     target_dir = make_storage_directory(os.path.join(hub_path, 'img-downsized_archive'))\n",
    "    for f_to_move in move_files:\n",
    "        print(f_to_move, target_dir)\n",
    "#         shutil.move(f_to_move, target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress image files to harddrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/TOSHIBA-22/hpdmobile_dataset/H2-IMAGES/H2-RS4-images\n",
      "from: /Volumes/TOSHIBA-22/hpdmobile_dataset/H2-IMAGES/H2-RS4-images to: /Volumes/SAMSUNG-4/H2/H2_RS4_IMAGES\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0306292ce17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{home}_{hub}_IMAGES'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'from: {to_compress} to: {destination}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_compress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done compressing '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger)\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                         \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adding '%s'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m     def writestr(self, zinfo_or_arcname, data,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h2_paths = glob('/Volumes/TOSHIBA-22/hpdmobile_dataset/H2-IMAGES/*-images')\n",
    "# print(h2_paths)\n",
    "# print(home)\n",
    "for hub_path in h2_paths[2:]:\n",
    "    print(hub_path)\n",
    "    hub = os.path.basename(hub_path).split('-')[1]\n",
    "#     print(hub)\n",
    "    to_compress = hub_path\n",
    "    destination = os.path.join(dest, home, f'{home}_{hub}_IMAGES')\n",
    "    print(f'from: {to_compress} to: {destination}')\n",
    "    shutil.make_archive(destination, 'zip', to_compress)\n",
    "    print('done compressing ', destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS1\n",
      "from: /Volumes/TOSHIBA-22/H2-red/RS1/img-downsized-32 to: /Volumes/SAMSUNG-4/H2/H2_RS1_IMAGES\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/TOSHIBA-22/H2-red/RS1/img-downsized-32'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3101bb44bad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{home}_{hub}_IMAGES'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'from: {to_compress} to: {destination}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_compress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done compressing '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0mbase_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/TOSHIBA-22/H2-red/RS1/img-downsized-32'"
     ]
    }
   ],
   "source": [
    "for hub_path in hub_paths:\n",
    "    hub = os.path.basename(hub_path.strip('/'))\n",
    "    print(hub)\n",
    "    to_compress = os.path.join(hub_path, 'img-downsized-32')\n",
    "    destination = os.path.join(dest, home, f'{home}_{hub}_IMAGES')\n",
    "    print(f'from: {to_compress} to: {destination}')\n",
    "    shutil.make_archive(destination, 'zip', to_compress)\n",
    "    print('done compressing ', destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~Move audio day-files not part of the set to an archive folder~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS1 16 15\n",
      "RS2 17 17\n",
      "RS3 17 17\n",
      "RS4 17 17\n",
      "RS5 17 17\n"
     ]
    }
   ],
   "source": [
    "# for hub_path in hub_paths:\n",
    "#     hub = os.path.basename(hub_path.strip('/'))\n",
    "#     day_files = glob(os.path.join(hub_path, 'processed_audio', 'audio_csv', '2019-*'))\n",
    "#     move_files = [f for f in day_files if os.path.basename(f) in all_days_dict[home]]\n",
    "#     print(hub, len(day_files), len(move_files))\n",
    "#     target_dir = make_storage_directory(os.path.join(hub_path, 'audio_csv_archive'))\n",
    "#     for f_to_move in move_files:\n",
    "#         print(f_to_move, target_dir)\n",
    "# #         shutil.move(f_to_move, target_dir)\n",
    "# #         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine hub-folders for audio into one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maggie/Desktop/HDstorage\n",
      "RS1 37 35\n",
      "RS2 37 35\n",
      "RS3 37 35\n",
      "RS4 37 35\n",
      "RS5 37 35\n"
     ]
    }
   ],
   "source": [
    "print(save_path)\n",
    "for hub_path in hub_paths:\n",
    "    hub = os.path.basename(hub_path.strip('/'))\n",
    "    day_dirs = glob(os.path.join(hub_path, 'processed_audio', 'audio_csv', '2019-*'))\n",
    "    copy_dirs = [d for d in day_dirs if os.path.basename(d) in all_days_dict[home]]\n",
    "    not_in_dirs = [d for d in day_dirs if os.path.basename(d) not in all_days_dict[home]]\n",
    "    print(hub, len(day_dirs), len(copy_dirs))\n",
    "#     print(not_in_dirs)\n",
    "    target_dir = make_storage_directory(os.path.join(save_path, home, f'{home}_AUDIO', f'{home}_{hub}_AUDIO'))\n",
    "    for c_dir in copy_dirs:\n",
    "        date = os.path.basename(c_dir)\n",
    "        fname = os.path.join(target_dir, date)\n",
    "        shutil.copytree(c_dir, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress audio files to harddrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: /Users/maggie/Desktop/HDstorage/H4/H4_AUDIO/H4_RS1_AUDIO to: /Volumes/SAMSUNG-4/H4/H4_AUDIO/H4_RS1_AUDIO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Volumes/SAMSUNG-4/H4/H4_AUDIO/H4_RS1_AUDIO.zip'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Compressing \n",
    "\n",
    "# comp_fname =  os.path.join(f'{home}_AUDIO', f'{home}_RS1_AUDIO')\n",
    "# to_compress = os.path.join(save_path, home, comp_fname)\n",
    "# destination = os.path.join(dest, home, comp_fname)\n",
    "# print(f'from: {to_compress} to: {destination}')\n",
    "# shutil.make_archive(destination, 'zip', to_compress)\n",
    "# # print('done compressing ', destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: /Users/maggie/Desktop/HDstorage/H3/H3_AUDIO to: /Volumes/SAMSUNG-4/H3/H3_AUDIO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Volumes/SAMSUNG-4/H3/H3_AUDIO.zip'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = '/Users/maggie/Desktop/HDstorage'\n",
    "\n",
    "to_path = make_storage_directory(os.path.join(dest, home))\n",
    "\n",
    "to_compress = os.path.join(directory_path, home, f'{home}_AUDIO')\n",
    "destination = os.path.join(to_path, os.path.basename(to_compress.strip('/')))\n",
    "\n",
    "print(f'from: {to_compress} to: {destination}')\n",
    "shutil.make_archive(destination, 'zip', to_compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Environmental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change name of files to match other conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS1\n",
      "RS1 53 35\n",
      "RS2\n",
      "RS2 57 35\n",
      "RS3\n",
      "RS3 48 35\n",
      "RS4\n",
      "RS4 56 35\n",
      "RS5\n",
      "RS5 59 35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for hub_path in hub_paths:\n",
    "    hub = os.path.basename(hub_path.strip('/'))\n",
    "    print(hub)\n",
    "    day_files = glob(os.path.join(hub_path, 'processed_env', 'CSV-raw', '*.csv'))\n",
    "    copy_files = [f for f in day_files if os.path.basename(f).split('_')[2].rstrip('.csv') in all_days_dict[home]]\n",
    "    print(hub, len(day_files), len(copy_files))\n",
    "    target_dir = make_storage_directory(os.path.join(save_path, home, f'{home}_ENVIRONMENTAL', f'{home}_{hub}_ENV'))\n",
    "    for f in copy_files:\n",
    "        date = os.path.basename(f).split('_')[2].rstrip('.csv')\n",
    "        fname = os.path.join(target_dir, f'{date}_{hub}_{home}_env.csv')\n",
    "        shutil.copy(f, fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress env to harddrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: /Users/maggie/Desktop/HDstorage/H3/H3_ENVIRONMENTAL to: /Volumes/SAMSUNG-4/H3/H3_ENVIRONMENTAL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Volumes/SAMSUNG-4/H3/H3_ENVIRONMENTAL.zip'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = '/Users/maggie/Desktop/HDstorage'\n",
    "\n",
    "to_path = make_storage_directory(os.path.join(dest, home))\n",
    "\n",
    "to_compress = os.path.join(directory_path, home, f'{home}_ENVIRONMENTAL')\n",
    "destination = os.path.join(to_path, os.path.basename(to_compress.strip('/')))\n",
    "\n",
    "print(f'from: {to_compress} to: {destination}')\n",
    "shutil.make_archive(destination, 'zip', to_compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy over relevant days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cc9cb048ac54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mday_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GroundTruth/GroundTruth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*_groundtruth.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcopy_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mday_files\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_days_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_storage_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{home}_GROUNDTRUTH'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "day_files = glob(os.path.join(from_path, 'GroundTruth/GroundTruth', '*_groundtruth.csv'))\n",
    "\n",
    "copy_files = [f for f in day_files if os.path.basename(f).split('_')[0] in all_days_dict[home]]\n",
    "print(copy_files)\n",
    "save_loc = make_storage_directory(os.path.join(save_path, home, f'{home}_GROUNDTRUTH'))\n",
    "\n",
    "# for f in copy_files:\n",
    "#     dest_fname = os.path.join(save_loc, os.path.basename(f))\n",
    "#     shuutil.copy(f, dest_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_paths = glob(os.path.join(path, 'GroundTruth/GroundTruth', '*_groundtruth.csv'))\n",
    "\n",
    "for occ_file in occ_paths:\n",
    "\n",
    "    to_compress = occ_file\n",
    "    destination = os.path.join(dest, home, f'{home}_{hub}_IMAGES')\n",
    "    print(f'from: {to_compress} to: {destination}')\n",
    "    shutil.make_archive(destination, 'zip', to_compress)\n",
    "    print('done compressing ', destination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### H2 - dark image investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/TOSHIBA-22/H2-red/Summaries/H2-RS1-img-summary.txt', '/Volumes/TOSHIBA-22/H2-red/Summaries/H2-RS2-img-summary.txt', '/Volumes/TOSHIBA-22/H2-red/Summaries/H2-RS4-img-summary.txt', '/Volumes/TOSHIBA-22/H2-red/Summaries/H2-RS5-img-summary.txt']\n",
      "            RS1_Capt  RS1_Dark  RS1_Img  RS2_Capt  RS2_Dark  RS2_Img  \\\n",
      "2019-03-01       NaN       NaN      NaN      0.27      0.00      NaN   \n",
      "2019-03-02       NaN       NaN      NaN      1.00      0.21      NaN   \n",
      "2019-03-03       NaN       NaN      NaN      1.00      0.09      NaN   \n",
      "2019-03-04       NaN       NaN      NaN      1.00      0.48      NaN   \n",
      "2019-03-05       NaN       NaN      NaN      1.00      0.25      NaN   \n",
      "2019-03-06       NaN       NaN      NaN      1.00      0.25      NaN   \n",
      "2019-03-07       NaN       NaN      NaN      1.00      0.20      NaN   \n",
      "2019-03-08       NaN       NaN      NaN      1.00      0.00      NaN   \n",
      "2019-03-09       NaN       NaN      NaN      1.00      0.21      NaN   \n",
      "2019-03-10       NaN       NaN      NaN      0.96      0.17      NaN   \n",
      "2019-03-11       NaN       NaN      NaN      0.52      0.21      NaN   \n",
      "2019-03-12      0.09      0.09      NaN      0.26      0.00      NaN   \n",
      "2019-03-13      0.88      0.25     0.75      1.00      0.22     0.78   \n",
      "2019-03-14      0.96      0.37     0.63      1.00      0.35     0.65   \n",
      "2019-03-15      1.00      0.37     0.63      1.00      0.35     0.65   \n",
      "2019-03-16      1.00      0.30     0.70      1.00      0.29     0.71   \n",
      "2019-03-17      1.00      0.32     0.68      1.00      0.20     0.80   \n",
      "2019-03-18      1.00      0.44     0.56      1.00      0.23     0.77   \n",
      "2019-03-19      1.00      0.30     0.70      1.00      0.04     0.96   \n",
      "2019-03-20      1.00      0.40     0.60      1.00      0.35     0.65   \n",
      "2019-03-21      1.00      0.49     0.51      1.00      0.47     0.53   \n",
      "2019-03-22      1.00      0.29     0.71      1.00      0.27     0.73   \n",
      "2019-03-23      1.00      0.14     0.86      1.00      0.13     0.87   \n",
      "2019-03-24      1.00      0.09     0.91      1.00      0.00     1.00   \n",
      "2019-03-25      1.00      0.40     0.60      1.00      0.17     0.83   \n",
      "2019-03-26      0.99      0.23     0.76      0.93      0.17     0.76   \n",
      "2019-03-27      1.00      0.11     0.89      1.00      0.09     0.91   \n",
      "2019-03-28      1.00      0.24     0.76      1.00      0.23     0.77   \n",
      "2019-03-29      1.00      0.44     0.56      0.66      0.25     0.41   \n",
      "2019-03-30      1.00      0.24      NaN      0.26      0.07      NaN   \n",
      "2019-03-31      1.00      0.14      NaN      0.18      0.02      NaN   \n",
      "2019-04-01      1.00      0.20      NaN      0.17      0.03      NaN   \n",
      "2019-04-02      0.83      0.15      NaN      0.16      0.02      NaN   \n",
      "\n",
      "            RS4_Capt  RS4_Dark  RS4_Img  RS5_Capt  RS5_Dark  RS5_Img  \n",
      "2019-03-01      0.20       0.0      NaN       NaN       NaN      NaN  \n",
      "2019-03-02       NaN       NaN      NaN       NaN       NaN      NaN  \n",
      "2019-03-03       NaN       NaN      NaN       NaN       NaN      NaN  \n",
      "2019-03-04       NaN       NaN      NaN       NaN       NaN      NaN  \n",
      "2019-03-05       NaN       NaN      NaN       NaN       NaN      NaN  \n",
      "2019-03-06       NaN       NaN      NaN       NaN       NaN      NaN  \n",
      "2019-03-07       NaN       NaN      NaN      1.00      0.20      NaN  \n",
      "2019-03-08       NaN       NaN      NaN      1.00      0.00      NaN  \n",
      "2019-03-09       NaN       NaN      NaN      1.00      0.20      NaN  \n",
      "2019-03-10       NaN       NaN      NaN      0.96      0.16      NaN  \n",
      "2019-03-11       NaN       NaN      NaN      0.52      0.20      NaN  \n",
      "2019-03-12      0.26       0.0      NaN      0.20      0.00      NaN  \n",
      "2019-03-13      1.00       0.0     1.00      1.00      0.24     0.76  \n",
      "2019-03-14      1.00       0.0     1.00      1.00      0.35     0.65  \n",
      "2019-03-15      1.00       0.0     1.00      1.00      0.35     0.65  \n",
      "2019-03-16      1.00       0.0     1.00      1.00      0.29     0.71  \n",
      "2019-03-17      1.00       0.0     1.00      1.00      0.20     0.80  \n",
      "2019-03-18      1.00       0.0     1.00      1.00      0.23     0.77  \n",
      "2019-03-19      1.00       0.0     1.00      1.00      0.04     0.96  \n",
      "2019-03-20      1.00       0.0     1.00      1.00      0.35     0.65  \n",
      "2019-03-21      1.00       0.0     1.00      1.00      0.47     0.53  \n",
      "2019-03-22      1.00       0.0     1.00      1.00      0.27     0.73  \n",
      "2019-03-23      1.00       0.0     1.00      1.00      0.13     0.87  \n",
      "2019-03-24      1.00       0.0     1.00      1.00      0.00     1.00  \n",
      "2019-03-25      1.00       0.0     1.00      1.00      0.17     0.83  \n",
      "2019-03-26      0.99       0.0     0.99      0.98      0.18     0.80  \n",
      "2019-03-27      1.00       0.0     1.00      1.00      0.10     0.90  \n",
      "2019-03-28      1.00       0.0     1.00      1.00      0.22     0.78  \n",
      "2019-03-29      1.00       0.0     1.00      1.00      0.35     0.65  \n",
      "2019-03-30      1.00       0.0      NaN      1.00      0.23      NaN  \n",
      "2019-03-31      1.00       0.0      NaN      1.00      0.12      NaN  \n",
      "2019-04-01      1.00       0.0      NaN      1.00      0.19      NaN  \n",
      "2019-04-02      0.84       0.0      NaN      0.84      0.13      NaN  \n"
     ]
    }
   ],
   "source": [
    "summaries = glob('/Volumes/TOSHIBA-22/H2-red/Summaries/*-img-summary.txt')\n",
    "print(summaries)\n",
    "\n",
    "img_csv_summary = '/Users/maggie/Desktop/image_df_counts.csv'\n",
    "\n",
    "summary_df = pd.read_csv(img_csv_summary, index_col='Unnamed: 0')\n",
    "\n",
    "hub_dfs = []\n",
    "for txtfile in summaries:\n",
    "    txt_df = pd.read_csv(txtfile, delimiter=' ', usecols=['day', '%Capt', '%Dark'], index_col='day')\n",
    "#     print(txt_df.columns)\n",
    "    hub = os.path.basename(txtfile).split('-')[1]\n",
    "#     print(hub)\n",
    "    col_names = [f'{hub}_Capt', f'{hub}_Dark']\n",
    "    txt_df.columns = col_names\n",
    "    hub_dfs.append(txt_df)\n",
    "\n",
    "hub_dfs.append(summary_df)\n",
    "all_df = pd.concat(hub_dfs, axis=1)\n",
    "all_df = all_df.reindex(sorted(all_df.columns), axis=1)\n",
    "all_df = all_df.sort_index(axis=0)\n",
    "print(all_df)\n",
    "\n",
    "all_df.to_csv('/Users/maggie/Desktop/H2_all_images_summary.csv')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
